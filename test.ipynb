{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12969\\AppData\\Local\\Temp\\ipykernel_20460\\805292683.py:5: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(model_name='bge-large-zh-v1.5')\n",
      "d:\\anaconda3\\envs\\chatglm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader, PDFMinerLoader, UnstructuredMarkdownLoader\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, CharacterTextSplitter\n",
    "embedding = HuggingFaceEmbeddings(model_name='bge-large-zh-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.load_local('./vectorstore/1', embedding, \"1742380748273\", allow_dangerous_deserialization=True)\n",
    "docs = db.similarity_search('唯一的真理是什么', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='dcf06aab-8261-485a-b470-0354a8c5a3d8', metadata={'source': 'uploads\\\\1742380748273.txt'}, page_content='The only thing that words in this world\\n这世上唯一有效的真理是\\nis that you treat others\\n就是以他人对待你的方式\\nas they treat you\\n对待他人\\nThose that has treated me with kindness\\n待我以礼者\\nI will repay they kindness ten fold\\n滴水之恩我以涌泉相报\\nAnd those……\\n至于那些……\\nThey treat me with injustice!\\n待我不公之人！\\nThey used me\\n利用我之人\\nThey hurt me down\\n伤害我之人\\nThey hurt me friends\\n伤我友人\\nI shall repay that in justice a thousand times over\\n此等不公我将以千倍奉还。\\n\\n\\n“太阳所照之处皆为我们的国土。国王的更替就像太阳的升落。有一天，我的时代将随着太阳的落下而逝去，而它将会为你升起，当你成为新的王。”'),\n",
       " Document(id='eb635f20-351d-43d9-a531-d4516eda29d5', metadata={'source': 'uploads\\\\1742380748273.txt'}, page_content='#80000000\\n\\n机考参考：\\n递归：LeetCode70、112、509\\n分治：LeetCode23、169、240\\n单调栈：LeetCode84、85、739、503\\n并查集：LeetCode547、200、684\\n滑动窗口：LeetCode209、3、1004、1208\\n前缀和：LeetCode724、560、437、1248\\n差分：LeetCode1094、121、122\\n拓扑排序：LeetCode210\\n字符串：LeetCode5、20、43、93\\n二分查找：LeetCode33、34\\nBFS：LeetCode127、139、130、529、815\\nDFS&回溯：：LeetCode934、685、1102、531、533、113、332、337\\n动态规划：LeetCode213、123、62、63、361、1230\\n贪心算法：LeetCode55、435、621、452\\n字典树：LeetCode820、208、648'),\n",
       " Document(id='cd0251ac-9583-4940-89a6-95caa5ada767', metadata={'source': 'uploads\\\\1742380748273.txt'}, page_content='https://maoyetrpg.com/ceka/list?coc7_496515\\n\\n    always @(posedge clk) begin:one\\n        integer i;\\n        for(i=0;i<=23;i=i+1)\\n        begin\\n            sw[i]<=ddata[i];\\n        end\\n    end\\n\\n\\nPendingFileRenameOperations\\n\\\\??\\\\c:\\\\Config.Msi\\\\965fe7f.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965fe89.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965fe8b.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965fe94.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965fe96.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965fe97.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965fe98.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff5c.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff70.rbf'),\n",
       " Document(id='222a7148-728c-4fbc-a84a-a5ae910c5d60', metadata={'source': 'uploads\\\\1742380748273.txt'}, page_content='\\\\??\\\\c:\\\\Config.Msi\\\\965ff80.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff81.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff82.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff84.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff85.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff86.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff88.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff89.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff8a.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff8b.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff8c.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff8d.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff8e.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff8f.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff92.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff93.rbf'),\n",
       " Document(id='9968a969-29bc-4557-b2e9-b62053b88778', metadata={'source': 'uploads\\\\1742380748273.txt'}, page_content='\\\\??\\\\c:\\\\Config.Msi\\\\965ff70.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff72.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff73.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff74.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff75.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff76.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff77.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff78.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff79.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff7a.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff7b.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff7c.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff7d.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff7e.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff7f.rbf\\n\\n\\\\??\\\\c:\\\\Config.Msi\\\\965ff80.rbf')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(base_url=\"http://127.0.0.1:9997/v1\", api_key=\"not used actually\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"qwen2.5-instruct\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the largest animal?\"}\n",
    "    ]\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection error: HTTPConnectionPool(host='127.0.0.1', port=9997): Max retries exceeded with url: /v1 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001EB52D58CA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def test_connection(base_url):\n",
    "    try:\n",
    "        response = requests.get(base_url)\n",
    "        response.raise_for_status()\n",
    "        print(\"Connection successful\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Connection error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = 'http://127.0.0.1:9997/v1'\n",
    "    test_connection(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from neo4j import GraphDatabase\n",
    "import os\n",
    "\n",
    "class RAG:\n",
    "    def __init__(self, llm_params, embedding_model, uri, user, password):\n",
    "        self.app = Flask(__name__)\n",
    "        self.llm = ChatOpenAI(\n",
    "            **llm_params\n",
    "        )\n",
    "        self.course = None\n",
    "        self.retriever = None\n",
    "        self.chain = None\n",
    "        self.embedding = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        self._setup_routes()\n",
    "\n",
    "    def _initial_rag(self):\n",
    "        base_path = f\"./vectorstore/{self.course}\"\n",
    "        if os.path.exists(base_path):\n",
    "            db = None\n",
    "            for file in os.listdir(base_path):\n",
    "                if file.endswith(\".faiss\"):\n",
    "                    if db is None:\n",
    "                        db = FAISS.load_local(base_path, self.embedding, file.split('.')[0], allow_dangerous_deserialization=True)\n",
    "                    else:\n",
    "                        temp_db = FAISS.load_local(base_path, self.embedding, file.split('.')[0], allow_dangerous_deserialization=True)\n",
    "                        db.merge_from(temp_db)\n",
    "            self.retriever = db.as_retriever(\n",
    "                search_type=\"similarity_score_threshold\", \n",
    "                search_kwargs={\n",
    "                    \"k\": 4,\n",
    "                    \"score_threshold\": 0.2\n",
    "                })\n",
    "            template = \"\"\"\n",
    "            【指令】根据已知信息，简洁和专业的来回答问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题”，不允许在答案中添加编造成分，答案请使用中文，确保回答准确、完整。\n",
    "            【已知信息】\n",
    "            {context}\n",
    "\n",
    "            【问题】\n",
    "            {question}\n",
    "            \"\"\"\n",
    "        else:\n",
    "            self.retriever = None\n",
    "            template = \"\"\"\n",
    "            【指令】答案请使用中文，确保回答准确、完整。\n",
    "            【问题】\n",
    "            {question}\n",
    "            \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        self.chain = prompt | self.llm | StrOutputParser()\n",
    "\n",
    "    def _combine_documents(self, docs):\n",
    "        combined_docs = []\n",
    "        for i, doc in enumerate(docs):\n",
    "            combined_content = f\"Document {i+1}:\\n\"\n",
    "            combined_content += f\"Content:\\n{doc.page_content}\\n\"\n",
    "            combined_content += \"Metadata:\\n\"\n",
    "            for key, value in doc.metadata.items():\n",
    "                combined_content += f\"{key}: {value}\\n\"\n",
    "            combined_docs.append(combined_content.strip())\n",
    "        return \"\\n\\n\".join(combined_docs)\n",
    "    \n",
    "    def _query_neo4j(self, question):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(\"MATCH (n) WHERE n.name CONTAINS $question RETURN n\", question=question)\n",
    "            nodes = result.data()\n",
    "            return nodes\n",
    "\n",
    "    def _setup_routes(self):\n",
    "        @self.app.route(\"/ask\", methods=[\"POST\"])\n",
    "        def ask():\n",
    "            data = request.json\n",
    "            course = data.get(\"course\")\n",
    "            question = data.get(\"question\")\n",
    "            if not question:\n",
    "                return jsonify({\"error\": \"Question is required\"}), 400\n",
    "            try:\n",
    "                if not self.course or self.course != course:\n",
    "                    self.course = course\n",
    "                    self._initial_rag()\n",
    "                context = \"\"\n",
    "                if self.retriever:\n",
    "                    context = self._combine_documents(self.retriever.invoke(question))\n",
    "                neo4j_context = self._query_neo4j(question)\n",
    "                result = self.chain.invoke({\n",
    "                    \"question\": question,\n",
    "                    \"context\": context\n",
    "                })\n",
    "                return jsonify({\n",
    "                    \"answer\": result,\n",
    "                    \"context\": context\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"处理请求时出错: {str(e)}\")\n",
    "                return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "    def run(self, host=\"0.0.0.0\", port=5000):\n",
    "        self.app.run(host=host, port=port)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    llm_params = {\n",
    "        \"model\":'deepseek-chat',\n",
    "        \"openai_api_key\":\"sk-d1d1f9c2fa7547089a6e67912316bc3f\",\n",
    "        \"openai_api_base\":'https://api.deepseek.com',\n",
    "        \"max_tokens\":1024\n",
    "    }\n",
    "    embedding_model = 'bge-large-zh-v1.5'\n",
    "    uri = \"bolt://localhost:7687\"\n",
    "    username = \"neo4j\"\n",
    "    password = \"ytt252011\"\n",
    "\n",
    "    service = RAG(llm_params, embedding_model, uri, username, password)\n",
    "    service.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import json\n",
    "from langchain.llms import Tongyi\n",
    "\n",
    "llm = Tongyi()\n",
    "\n",
    "# Extract entities from text 定义抽取实体的类\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, json_data: dict):\n",
    "        names = []\n",
    "        if 'entities' in json_data:\n",
    "            for entity in json_data['entities']:\n",
    "                names.append(entity['entity'])\n",
    "        return cls(names=names)\n",
    "\n",
    "entity_query = \"Where did Marie Curie work?\"\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Entities)\n",
    "\n",
    "# 更新 ChatPromptTemplate 以包含新的提示词\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}. Please ensure the output is in valid JSON format.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 创建提示模板\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# 格式化输入\n",
    "_input = chat_prompt.format_prompt(question=entity_query)\n",
    "\n",
    "# 获取 LLM 输出\n",
    "output = llm(_input.to_string())\n",
    "\n",
    "# 解析输出\n",
    "parsed_output = json.loads(output)\n",
    "\n",
    "# 使用自定义的 from_json 方法解析输出\n",
    "entities = Entities.from_json(parsed_output)\n",
    "\n",
    "# 获取 names 列表\n",
    "names = entities.names\n",
    "print(names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12969\\AppData\\Local\\Temp\\ipykernel_19956\\3793304975.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(model_name=\"bge-large-zh-v1.5\")\n",
      "d:\\anaconda3\\envs\\chatglm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取到的问题：\n",
      "{'questionid': 5, 'studentid': 2021102549, 'courseid': 1, 'title': '如何理解LL(1)文法的预测分析表构建？', 'content': '在学习编译原理时，对LL(1)文法的预测分析表构建步骤不太清楚，特别是First集和Follow集的计算部分，希望能得到详细的解释。', 'tags': ['作业疑问', '概念理解'], 'images': ['/uploads/1739954446173.jpg'], 'status': 'open', 'pendingTime': '2025-03-02T16:07:29.079Z', 'createdAt': '2025-02-19T08:40:46.338Z', 'updatedAt': '2025-03-02T17:35:48.901Z', 'Student': {'username': '颜婷婷', 'nickname': 'QWQ', 'avatar': '/uploads/1740848107838.jpg'}, 'Course': {'coursename': '编译原理', 'teacherid': 1}}\n",
      "{'questionid': 13, 'studentid': 2021102549, 'courseid': 1, 'title': 'test', 'content': 'test', 'tags': ['编程问题'], 'images': [], 'status': 'locked', 'pendingTime': None, 'createdAt': '2025-02-28T16:17:30.368Z', 'updatedAt': '2025-03-02T17:33:36.625Z', 'Student': {'username': '颜婷婷', 'nickname': 'QWQ', 'avatar': '/uploads/1740848107838.jpg'}, 'Course': {'coursename': '编译原理', 'teacherid': 1}}\n",
      "推荐的问题：\n",
      "问题 1: 在学习编译原理时，对LL(1)文法的预测分析表构建步骤不太清楚，特别是First集和Follow集的计算部分，希望能得到详细的解释。 (提问者: QWQ)\n",
      "问题 2: test (提问者: QWQ)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import requests\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"bge-large-zh-v1.5\")\n",
    "api_url = \"http://localhost:8001/api/questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题 1: 如何理解LL(1)文法的预测分析表构建？ - 在学习编译原理时，对LL(1)文法的预测分析表构建步骤不太清楚，特别是First集和Follow集的计算部分，希望能得到详细的解释。 (相似度: 0.64)\n"
     ]
    }
   ],
   "source": [
    "def fetch_related_questions(course_id, current_question):\n",
    "    params = {\"courseIds\": [course_id]}\n",
    "    try:\n",
    "        response = requests.get(api_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        questions = response.json()\n",
    "        current_embedding = embedding.embed_query(current_question)\n",
    "        question_similarities = []\n",
    "        for question in questions:\n",
    "            combined_text = f\"{question['title']} {question['content']}\"\n",
    "            question_embedding = embedding.embed_query(combined_text)\n",
    "            similarity = cosine_similarity([current_embedding], [question_embedding])[0][0]\n",
    "            question_similarities.append((question, similarity))\n",
    "        sorted_questions = sorted(\n",
    "            question_similarities, key=lambda x: x[1], reverse=True\n",
    "        )[:3]\n",
    "        return [\n",
    "            {\n",
    "                \"title\": q[\"title\"],\n",
    "                \"content\": q[\"content\"],\n",
    "                \"similarity\": sim,\n",
    "            }\n",
    "            for q, sim in sorted_questions if sim > 0.5\n",
    "        ]\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching related questions: {e}\")\n",
    "        return []\n",
    "\n",
    "# 示例调用\n",
    "course_id = 1\n",
    "current_question = \"LL（1）文法是指什么？\"\n",
    "similar_questions = fetch_related_questions(course_id, current_question)\n",
    "\n",
    "# 打印结果\n",
    "for i, q in enumerate(similar_questions, 1):\n",
    "    print(f\"问题 {i}: {q['title']} - {q['content']} (相似度: {q['similarity']:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatglm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
